{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dangerous-brazil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5c700fe7f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import theseus as th\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sapphire-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a uniformly random point of the 2-sphere\n",
    "def random_S2():\n",
    "    theta = torch.rand(()) * math.tau\n",
    "    z = torch.rand(()) * 2 - 1\n",
    "    r = torch.sqrt(1 - z**2)\n",
    "    return torch.tensor([r*torch.cos(theta), r*torch.sin(theta), z]).double()\n",
    "\n",
    "# returns a uniformly random point of the 3-sphere\n",
    "def random_S3():\n",
    "    u, v, w = torch.rand(3)\n",
    "    return torch.tensor([\n",
    "        torch.sqrt(1-u) * torch.sin(math.tau*v),\n",
    "        torch.sqrt(1-u) * torch.cos(math.tau*v),\n",
    "        torch.sqrt(u) * torch.sin(math.tau*w),\n",
    "        torch.sqrt(u) *torch.cos(math.tau*w)\n",
    "    ]).double()\n",
    "\n",
    "def randomSmallQuaternion(max_degrees, min_degrees = 0):\n",
    "    x,y,z = random_S2()\n",
    "    theta = (min_degrees + (max_degrees - min_degrees) * torch.rand(())) * math.tau / 360.0\n",
    "    c, s = torch.cos(theta), torch.sin(theta)\n",
    "    return torch.tensor([c, s * x, s * y, s * z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4386abf5-3cc8-47c0-840e-ee40c230b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "\n",
    "def softLossCauchy(x, radius):\n",
    "    ratio = (x + radius) / radius\n",
    "    val = torch.log(ratio) * radius\n",
    "    der = 1.0 / ratio\n",
    "    return val, der\n",
    "    \n",
    "def softLossHuberLike(x, radius):\n",
    "    ratio = (x + radius) / radius\n",
    "    sq = torch.sqrt(ratio)\n",
    "    val = (sq - 1)*radius\n",
    "    der = 0.5 / sq\n",
    "    return val, der\n",
    "\n",
    "softLoss = softLossHuberLike\n",
    "\n",
    "class ReprojErr(th.CostFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        camRot: th.SO3,\n",
    "        camTr: th.Point3,\n",
    "        lossRadius: th.Vector,\n",
    "        focalLength: th.Vector,\n",
    "        worldPoint: th.Vector,\n",
    "        imageFeaturePoint: th.Vector,\n",
    "        i: int,\n",
    "        name: Optional[str] = None\n",
    "    ):\n",
    "        super().__init__(cost_weight=\n",
    "                         th.ScaleCostWeight(th.Vector(data=torch.tensor([1.0], dtype=torch.float64), name=f\"weight_{i}\")), name=name)\n",
    "        self.camRot = camRot\n",
    "        self.camTr = camTr\n",
    "        self.lossRadius = lossRadius\n",
    "        self.focalLength = focalLength\n",
    "        self.worldPoint = worldPoint\n",
    "        self.imageFeaturePoint = imageFeaturePoint\n",
    "\n",
    "        self.register_optim_vars([\"camRot\", \"camTr\"])\n",
    "        self.register_aux_vars([\"lossRadius\", \"focalLength\", f\"worldPoint\", f\"imageFeaturePoint\"])\n",
    "\n",
    "    def error(self) -> torch.Tensor:\n",
    "        camObsPoint = self.camRot.rotate(self.worldPoint) + self.camTr\n",
    "        projObsPoint = camObsPoint[:, :2] / camObsPoint[:, 2:3] * self.focalLength.data\n",
    "        err = projObsPoint - self.imageFeaturePoint.data\n",
    "        # return err # no lossRadius\n",
    "        \n",
    "        errNorm = torch.norm(err, dim=1).unsqueeze(1)\n",
    "        expLoss = torch.exp(lossRadius.data)\n",
    "        \n",
    "        val, der = softLoss(errNorm, expLoss)\n",
    "        return val\n",
    "\n",
    "    def jacobians(self) -> Tuple[List[torch.Tensor], torch.Tensor]:\n",
    "        camObsPoint = self.camRot.rotate(self.worldPoint) + self.camTr\n",
    "        batch_size = self.camRot.shape[0]\n",
    "        X = torch.zeros((batch_size, 3, 3), dtype=torch.float64)\n",
    "        rotApplVec = self.worldPoint\n",
    "        X[:, 0, 1] = rotApplVec[:, 2]\n",
    "        X[:, 0, 2] = -rotApplVec[:, 1]\n",
    "        X[:, 1, 0] = -rotApplVec[:, 2]\n",
    "        X[:, 1, 2] = rotApplVec[:, 0]\n",
    "        X[:, 2, 0] = rotApplVec[:, 1]\n",
    "        X[:, 2, 1] = -rotApplVec[:, 0]\n",
    "        J = torch.cat((torch.bmm(self.camRot.data, X),\n",
    "                       torch.eye(3, 3).unsqueeze(0).repeat(batch_size, 1, 1)), dim=2)\n",
    "        #J = torch.zeros((self.camRot.shape[0], 3, 6), dtype=torch.float64)\n",
    "        #J[:, :, 3:6] = torch.eye(3, 3) # d/dTr\n",
    "        #J[:, :, :3] = torch.bmm(self.camRot.data, X)\n",
    "        \n",
    "        projObsPoint = (camObsPoint[:, :2] / camObsPoint[:, 2:]) * self.focalLength.data\n",
    "        dNum = J[:, 0:2, :]\n",
    "        NumDDen_Den = torch.bmm(camObsPoint[:, :2].unsqueeze(2), (J[:, 2, :] / camObsPoint[:, 2:3]).unsqueeze(1))\n",
    "        Dproj = ((dNum - NumDDen_Den) / camObsPoint[:, 2:].unsqueeze(2) * self.focalLength.data.unsqueeze(2))\n",
    "        err = projObsPoint - self.imageFeaturePoint.data\n",
    "        # return [Dproj[:, :, :3], Dproj[:, :, 3:]], err # no lossRadius\n",
    "\n",
    "        errNorm = torch.norm(err, dim=1).unsqueeze(1)\n",
    "        errDir = err / errNorm\n",
    "        normJac = torch.bmm(errDir.unsqueeze(1), Dproj)\n",
    "        expLoss = torch.exp(lossRadius.data)\n",
    "    \n",
    "        val, der = softLoss(errNorm, expLoss)\n",
    "        softJac = normJac * der.unsqueeze(1)\n",
    "        return [softJac[:, :, :3], softJac[:, :, 3:]], val \n",
    "\n",
    "        #retv = (torch.log(errNorm / expLoss + 1) * expLoss) ###.unsqueeze(1)\n",
    "        #retvJac = normJac * (expLoss / (errNorm + expLoss)).unsqueeze(1)\n",
    "        #outs = [retvJac[:, :, :3], retvJac[:, :, 3:]], retv # no lossRadius\n",
    "        # print([retvJac[:, :, :3], retvJac[:, :, 3:]], retv)\n",
    "        # print([retvJac[:, :, :3].shape, retvJac[:, :, 3:].shape], retv.shape)\n",
    "        # outs\n",
    "\n",
    "    def dim(self) -> int:\n",
    "        return 2\n",
    "    \n",
    "    # calls to() on the cost weight, variables and any internal tensors\n",
    "    def to(self, *args, **kwargs):\n",
    "        super().to(*args, **kwargs)\n",
    "        \n",
    "    def _copy_impl(self):\n",
    "        return ReprojErr(\n",
    "            camRot,\n",
    "            camTr,\n",
    "            lossRadius,\n",
    "            focalLength,\n",
    "            worldPoint,\n",
    "            imageFeaturePoint,\n",
    "            i,\n",
    "            name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06438d87-28e1-404c-8a3c-273f900d5248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[[-7.1198,  6.4039, -1.6803]],\n",
      "\n",
      "        [[-1.7732,  1.8758, -1.9139]],\n",
      "\n",
      "        [[-3.5158,  1.0741,  1.2059]],\n",
      "\n",
      "        [[-2.0341,  1.2564,  1.8737]]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>), tensor([[[10.4538, 12.2413, -1.1650]],\n",
      "\n",
      "        [[11.0321,  7.3501, -1.3624]],\n",
      "\n",
      "        [[ 0.4866,  8.0946, -1.1845]],\n",
      "\n",
      "        [[ 5.6645,  8.0648, -1.1017]]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)], tensor([[ 4.5845],\n",
      "        [ 6.2800],\n",
      "        [10.5406],\n",
      "        [ 8.7222]], dtype=torch.float64, grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "if not False:\n",
    "    camRot = th.SO3(torch.cat([randomSmallQuaternion(max_degrees = 20).unsqueeze(0) for _ in range(4)]), name=\"camRot\")\n",
    "    camTr = th.Point3(data=torch.zeros((4, 3), dtype=torch.float64), name=\"camTr\")\n",
    "    camTr.data[:, 2] += 5.0\n",
    "    focalLenght = th.Vector(data=torch.tensor([1000], dtype=torch.float64).repeat(4).unsqueeze(1), name=\"focalLength\")\n",
    "    lossRadius = th.Vector(data=torch.tensor([0], dtype=torch.float64).repeat(4).unsqueeze(1), name=\"lossRadius\")\n",
    "    worldPoint = th.Vector(data=torch.rand((4,3), dtype=torch.float64), name=\"worldPoint\")\n",
    "    camPoint = camRot.rotate(worldPoint) + camTr\n",
    "    imageFeaturePoint = th.Vector(data=camPoint[:, :2] / camPoint[:, 2:] + torch.rand((4,2)) * 50, name=\"imageFeaturePoint\")\n",
    "    r = ReprojErr(camRot=camRot, camTr=camTr,\n",
    "              focalLength=focalLenght,\n",
    "              lossRadius=lossRadius,\n",
    "              worldPoint=worldPoint,\n",
    "              imageFeaturePoint=imageFeaturePoint,\n",
    "              i=0)\n",
    "\n",
    "    r.lossRadius.data.requires_grad = True\n",
    "    print(r.jacobians())\n",
    "    (rotJac, trJac), err = r.jacobians()\n",
    "    # r.error().backward(torch.tensor([1,2,3,4]).unsqueeze(1))\n",
    "    # rotJac.backward(torch.rand(rotJac.shape))\n",
    "    trJac.backward(torch.rand(trJac.shape))\n",
    "    r.lossRadius.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7384f07a-8b06-4cb1-9698-9cf5970da621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|numJac-analiticJac|:  5.825480363364426e-07 4.86097621802588e-07\n"
     ]
    }
   ],
   "source": [
    "# unit test for Cost term\n",
    "camRot = th.SO3(torch.cat([randomSmallQuaternion(max_degrees = 20).unsqueeze(0) for _ in range(4)]), name=\"camRot\")\n",
    "camTr = th.Point3(data=torch.zeros((4, 3), dtype=torch.float64), name=\"camTr\")\n",
    "camTr.data[:, 2] += 5.0\n",
    "focalLenght = th.Vector(data=torch.tensor([1000], dtype=torch.float64).repeat(4).unsqueeze(1), name=\"focalLength\")\n",
    "lossRadius = th.Vector(data=torch.tensor([0], dtype=torch.float64).repeat(4).unsqueeze(1), name=\"lossRadius\")\n",
    "worldPoint = th.Vector(data=torch.rand((4,3), dtype=torch.float64), name=\"worldPoint\")\n",
    "camPoint = camRot.rotate(worldPoint) + camTr\n",
    "imageFeaturePoint = th.Vector(data=camPoint[:, :2] / camPoint[:, 2:] + torch.rand((4,2)) * 50, name=\"imageFeaturePoint\")\n",
    "r = ReprojErr(camRot=camRot, camTr=camTr,\n",
    "          focalLength=focalLenght,\n",
    "          lossRadius=lossRadius,\n",
    "          worldPoint=worldPoint,\n",
    "          imageFeaturePoint=imageFeaturePoint,\n",
    "          i=0)\n",
    "\n",
    "baseVal = r.error()\n",
    "baseCamRot = r.camRot.copy()\n",
    "baseCamTr = r.camTr.copy()\n",
    "nErr = baseVal.shape[1]\n",
    "nJac = torch.zeros((r.camRot.data.shape[0], nErr, 6), dtype=torch.float64)\n",
    "epsilon = 1e-8\n",
    "for i in range(6):\n",
    "    if i >= 3:\n",
    "        r.camTr = baseCamTr.copy()\n",
    "        r.camTr.data[:, i - 3] += epsilon\n",
    "        r.camRot = baseCamRot.copy()\n",
    "    else:\n",
    "        r.camTr = baseCamTr.copy()\n",
    "        v = torch.zeros((r.camRot.data.shape[0], 3), dtype=torch.float64)\n",
    "        v[:, i] += epsilon\n",
    "        r.camRot = baseCamRot.retract(v)\n",
    "    pertVal = r.error()\n",
    "    nJac[:, :, i] = (pertVal - baseVal) / epsilon\n",
    "\n",
    "rotNumJac = nJac[:, :, :3]\n",
    "trNumJac = nJac[:, :, 3:]\n",
    "\n",
    "(rotJac, trJac), _ = r.jacobians()\n",
    "\n",
    "print(\"|numJac-analiticJac|: \",\n",
    "    float(torch.norm(rotNumJac - rotJac)), float(torch.norm(trNumJac - trJac)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mounted-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_and_outliers(projPoints,\n",
    "                           noiseSize = 1,\n",
    "                           noiseLinear=True,\n",
    "                           proportionOutliers = 0.05,\n",
    "                           outlierDistance = 500):\n",
    "    \n",
    "    if noiseLinear:\n",
    "        featImagePoints = projPoints + noiseSize * (torch.rand(projPoints.shape, dtype=torch.float64) * 2 - 1)\n",
    "    else: # normal, stdDev = noiseSize\n",
    "        featImagePoints = projPoints + torch.normal(mean=torch.zeros(projPoints.shape), std=noiseSize, dtype=torch.float64)\n",
    "\n",
    "    # add real bad outliers\n",
    "    outliersMask = torch.rand(featImagePoints.shape[0]) < proportionOutliers\n",
    "    numOutliers = featImagePoints[outliersMask].shape[0]\n",
    "    featImagePoints[outliersMask] += outlierDistance * (torch.rand((numOutliers, projPoints.shape[1]),\n",
    "                                                                   dtype=projPoints.dtype) * 2 - 1)\n",
    "    return featImagePoints\n",
    "\n",
    "class LocalizationSample:\n",
    "    def __init__(self, num_points=60, focalLength=1000):\n",
    "        self.focalLength = th.Variable(data=torch.tensor([focalLength], dtype=torch.float64), name=\"focalLength\")\n",
    "        \n",
    "        # pts = [+/-10, +/-10, +/-1]\n",
    "        self.worldPoints = torch.cat([\n",
    "            torch.rand(2, num_points, dtype=torch.float64) * 20 - 10,\n",
    "            torch.rand(1, num_points, dtype=torch.float64)*2 - 1]\n",
    "        ).T\n",
    "        \n",
    "        # gtCamPos = [+/-3, +/-3, 5 +/-1]\n",
    "        gtCamPos = th.Point3(torch.tensor([[\n",
    "            torch.rand((), dtype=torch.float64) * 3,\n",
    "            torch.rand((), dtype=torch.float64) * 3,\n",
    "            5 + torch.rand((), dtype=torch.float64)]]), name=\"gtCamPos\")\n",
    "        self.gtCamRot = th.SO3(randomSmallQuaternion(max_degrees = 20), name=\"gtCamRot\")\n",
    "        self.gtCamTr = (-self.gtCamRot.rotate(gtCamPos)).copy(new_name=\"gtCamTr\")\n",
    "        \n",
    "        camPoints = self.gtCamRot.rotate(self.worldPoints) + self.gtCamTr\n",
    "        projPoints = camPoints[:, :2] / camPoints[:, 2:3] * self.focalLength.data\n",
    "        self.imageFeaturePoints = add_noise_and_outliers(projPoints)\n",
    "        \n",
    "        smallRot = th.SO3(randomSmallQuaternion(max_degrees = 0.3))\n",
    "        smallTr = torch.rand(3, dtype=torch.float64) * 0.1\n",
    "        self.obsCamRot = smallRot.compose(self.gtCamRot).copy(new_name=\"obsCamRot\")\n",
    "        self.obsCamTr = (smallRot.rotate(self.gtCamTr) + smallTr).copy(new_name=\"obsCamTr\")\n",
    "\n",
    "l = LocalizationSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3759e5-2b12-4a3f-8ae9-7d1c75fa4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimization problem\n",
    "camRot = l.obsCamRot.copy(new_name=\"camRot\")\n",
    "camTr = l.obsCamTr.copy(new_name=\"camTr\")\n",
    "lossRadius = th.Vector(1, name=\"lossRadius\", dtype=torch.float64)\n",
    "focalLength = th.Vector(1, name=\"focalLength\", dtype=torch.float64)\n",
    "\n",
    "# NOTE: if not set explicitly will crash using a weight of wrong type `float32`\n",
    "weight = th.ScaleCostWeight(th.Vector(data=torch.tensor([1.0], dtype=torch.float64), name=\"weight\"))\n",
    "\n",
    "# Set up objective\n",
    "objective = th.Objective(dtype=torch.float64)\n",
    "for i in range(len(l.worldPoints)):\n",
    "    worldPoint = th.Vector(data=l.worldPoints[i], name=f\"worldPoint_{i}\")\n",
    "    imageFeaturePoint = th.Vector(data=l.imageFeaturePoints[i], name=f\"imageFeaturePoint_{i}\")\n",
    "\n",
    "    optim_vars = [camRot, camTr]\n",
    "    aux_vars = [lossRadius, focalLength, worldPoint, imageFeaturePoint]\n",
    "    cost_function = ReprojErr(camRot=camRot, camTr=camTr,\n",
    "          focalLength=focalLength,\n",
    "          lossRadius=lossRadius,\n",
    "          worldPoint=worldPoint,\n",
    "          imageFeaturePoint=imageFeaturePoint,\n",
    "          i=i)\n",
    "    objective.add(cost_function)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = th.LevenbergMarquardt( # GaussNewton(\n",
    "    objective,\n",
    "    max_iterations=10,\n",
    "    step_size=0.5,\n",
    ")\n",
    "\n",
    "# Set up Theseus layer\n",
    "theseus_optim = th.TheseusLayer(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e361f3d3-b033-4bab-996d-939f162cee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "# NOTE: composition of SO3 rotations is often not a valid rotation (.copy fails)\n",
    "loc_samples = [LocalizationSample() for _ in range(1024)]\n",
    "batch_size = 128\n",
    "num_batches = (len(loc_samples) + batch_size - 1) // batch_size\n",
    "\n",
    "def get_batch(b):\n",
    "    assert b * batch_size < len(loc_samples)\n",
    "    batch_ls = loc_samples[b*batch_size:(b+1)*batch_size]\n",
    "    batch_data = {\n",
    "        'camRot': th.SO3(data=torch.cat([l.obsCamRot.data for l in batch_ls])),\n",
    "        'camTr': th.Point3(data=torch.cat([l.obsCamTr.data for l in batch_ls])),\n",
    "        'focalLength': th.Vector(data=torch.cat([l.focalLength.data.unsqueeze(1) for l in batch_ls]), name='focalLength')\n",
    "    }\n",
    "\n",
    "    # batch of 3d points and 2d feature points\n",
    "    for i in range(len(batch_ls[0].worldPoints)):\n",
    "        batch_data[f\"worldPoint_{i}\"] = th.Vector(data=torch.cat([l.worldPoints[i:i+1].data for l in batch_ls]), name=f\"worldPoint_{i}\")\n",
    "        batch_data[f\"imageFeaturePoint_{i}\"] = th.Vector(data=torch.cat([l.imageFeaturePoints[i:i+1].data for l in batch_ls]), name=f\"imageFeaturePoint_{i}\")\n",
    "\n",
    "    gtCamRot = th.SO3(data=torch.cat([l.gtCamRot.data for l in batch_ls]))\n",
    "    gtCamTr = th.Point3(data=torch.cat([l.gtCamTr.data for l in batch_ls]))\n",
    "    return batch_data, gtCamRot, gtCamTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa54498a-7ec9-4311-8486-ae3dec4368ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maurimo/git/venv_theseus_nocuda/lib64/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Error detected in BmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib64/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib64/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/maurimo/git/venv_theseus_nocuda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1380775/1238128260.py\", line 19, in <module>\n",
      "    theseus_outputs, info = theseus_optim.forward(theseus_inputs\n",
      "  File \"/home/maurimo/git/theseus/theseus/theseus_layer.py\", line 37, in forward\n",
      "    info = self.optimizer.optimize(**optimizer_kwargs)\n",
      "  File \"/home/maurimo/git/theseus/theseus/optimizer/optimizer.py\", line 39, in optimize\n",
      "    return self._optimize_impl(**kwargs)\n",
      "  File \"/home/maurimo/git/theseus/theseus/optimizer/nonlinear/nonlinear_optimizer.py\", line 254, in _optimize_impl\n",
      "    info = self._optimize_loop(\n",
      "  File \"/home/maurimo/git/theseus/theseus/optimizer/nonlinear/nonlinear_optimizer.py\", line 206, in _optimize_loop\n",
      "    self.retract_and_update_variables(\n",
      "  File \"/home/maurimo/git/theseus/theseus/optimizer/nonlinear/nonlinear_optimizer.py\", line 334, in retract_and_update_variables\n",
      "    new_var = var.retract(delta[:, var_idx : var_idx + var.dof()])\n",
      "  File \"/home/maurimo/git/theseus/theseus/geometry/manifold.py\", line 89, in retract\n",
      "    return self._retract_impl(delta)\n",
      "  File \"/home/maurimo/git/theseus/theseus/geometry/lie_group.py\", line 133, in _retract_impl\n",
      "    return self.compose(self.exp_map(delta))\n",
      "  File \"/home/maurimo/git/theseus/theseus/geometry/lie_group.py\", line 89, in compose\n",
      "    composition = self._compose_impl(variable2)\n",
      "  File \"/home/maurimo/git/theseus/theseus/geometry/so3.py\", line 156, in _compose_impl\n",
      "    ret = SO3(data = self.data @ so3_2.data)\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.DoubleTensor [128, 3, 3]], which is output 0 of AsStridedBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(loss\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m lossShape):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOK:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lossOk)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m model_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(loss)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/git/venv_theseus_nocuda/lib64/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/venv_theseus_nocuda/lib64/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.DoubleTensor [128, 3, 3]], which is output 0 of AsStridedBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "# Outer optimization loop\n",
    "lossRadius_tensor = torch.nn.Parameter(torch.tensor([-3], dtype=torch.float64))\n",
    "model_optimizer = torch.optim.Adam([lossRadius_tensor], lr=0.1)\n",
    "\n",
    "# print(f\"Initial a value: {a_tensor.item()}\")\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_b = []  # keep track of the current b values for each model in this epoch\n",
    "    for i in range(num_batches):\n",
    "        model_optimizer.zero_grad()\n",
    "        theseus_inputs, gtCamRot, gtCamTr = get_batch(i)\n",
    "        theseus_inputs['lossRadius'] = lossRadius_tensor.repeat(gtCamTr.data.shape[0]).unsqueeze(1)\n",
    "        # print(theseus_inputs['lossRadius'])\n",
    "        \n",
    "        # print(\"IN:\", theseus_inputs)\n",
    "        try:\n",
    "            theseus_outputs, info = theseus_optim.forward(theseus_inputs\n",
    "                                                    #, optimizer_kwargs={\"verbose\":True}\n",
    "                                                    )\n",
    "            #print('OK!')\n",
    "        except:\n",
    "            print('SKIP! error in forward...')\n",
    "            continue\n",
    "        # print(\"OUT:\", updated_inputs)\n",
    "\n",
    "        # objective.update(updated_inputs)\n",
    "        #print(gtCamRot.data.shape)\n",
    "        #print(updated_inputs['camRot'].data.shape)\n",
    "        #print(gtCamTr.data.shape)\n",
    "        #print(updated_inputs['camTr'].data.shape)\n",
    "        loss = torch.norm(10 * gtCamRot.data - theseus_outputs['camRot'], dim=(1,2), p=1) + \\\n",
    "                torch.norm(gtCamTr.data - theseus_outputs['camTr'], dim=1, p=1)\n",
    "        # Step 2.3: PyTorch backpropagation\n",
    "        #print(loss)\n",
    "        #print(loss < 10e5)\n",
    "        \n",
    "        #print('LOSS:', loss)\n",
    "        #print(\"OK:\", loss < 10e5)\n",
    "        lossShape = loss.shape\n",
    "        lossOk = loss < 10e5\n",
    "        loss = loss[lossOk]\n",
    "        if(loss.shape != lossShape):\n",
    "            print(\"LOK:\", lossOk)\n",
    "        loss.backward(torch.ones(loss.shape))\n",
    "        model_optimizer.step()\n",
    "\n",
    "        loss_value = torch.sum(loss).item()\n",
    "        epoch_loss += loss_value\n",
    "        \n",
    "        #print(f\"[{epoch}] Radius: exp({lossRadius_tensor.data.item()})={torch.exp(lossRadius_tensor.data).item()}\")\n",
    "        #print(\"RAD:\", lossRadius_tensor.data.item())\n",
    "    print(f\"Epoch: {epoch} Loss: {epoch_loss} Kernel Radius: exp({lossRadius_tensor.data.item()})={torch.exp(lossRadius_tensor.data).item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63533035-46c4-4aed-8e9a-06bc312977e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6f816-f0dd-4634-8c23-950eeaed7622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04660842-330a-42a4-a2c5-10d337c528fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327682af-c010-4620-8d03-7aa8200c672d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b15e5-6385-4cf1-9962-0b0248989684",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldCamRot = update_data['camRot'].copy()\n",
    "oldCamTr = update_data['camTr'].copy()\n",
    "\n",
    "updated_inputs, info = theseus_optim.forward(update_data, optimizer_kwargs={\"track_best_solution\": True, \"verbose\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d930589-f032-47a6-b74e-c784038855d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a20aa-80ac-44c9-8caf-3c7308f25f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldCamRot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b96a7-ac60-45df-9151-4f4ffda54291",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(gtCamRot.data - oldCamRot.data, dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3103d9c-24e9-4e2c-88f5-8fe88d8c3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(gtCamRot.data - updated_inputs['camRot'].data, dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d0b16-25ec-4e3f-8cca-5b2242156ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ls[0].gtCamRot.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066d2f6-63b9-4fd6-a3b5-00f137292c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data['camTr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176d526-ca54-4825-8b4d-e02cca3400e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ls[0].gtCamTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d853214-767e-457e-8fc8-d898bb14907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ls[0].obsCamTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6580f5-2fed-4c03-bb92-40bfabd95e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(theseus_optim.optimizer.linear_solver.linearization.ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1cd3b-2329-4559-89e9-a0eda5490f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c2868-6c59-404c-bb8c-0bd142f5df00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd278293-25eb-42fe-aeff-cfb14dbd9382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6253a-497f-40a9-a918-e8545d09aa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01ce37-191a-48ca-a411-5373b451c1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
